== Prutor ML Project : California Housing Dataset

== 1. Collect and Prepare Data


+*In[1]:*+
[source, ipython3]
----
import pandas as pd
import seaborn as sns
import numpy as np
import matplotlib.pyplot as plt
----


+*In[2]:*+
[source, ipython3]
----
###  Read housing dataset file
----


+*In[5]:*+
[source, ipython3]
----

df=pd.read_csv('housing.csv')
df
----


+*Out[5]:*+
----
[cols=",,,,,,,,,,",options="header",]
|===
| |longitude |latitude |housing_median_age |total_rooms |total_bedrooms
|population |households |median_income |median_house_value
|ocean_proximity
|0 |-122.23 |37.88 |41.0 |880.0 |129.0 |322.0 |126.0 |8.3252 |452600.0
|NEAR BAY

|1 |-122.22 |37.86 |21.0 |7099.0 |1106.0 |2401.0 |1138.0 |8.3014
|358500.0 |NEAR BAY

|2 |-122.24 |37.85 |52.0 |1467.0 |190.0 |496.0 |177.0 |7.2574 |352100.0
|NEAR BAY

|3 |-122.25 |37.85 |52.0 |1274.0 |235.0 |558.0 |219.0 |5.6431 |341300.0
|NEAR BAY

|4 |-122.25 |37.85 |52.0 |1627.0 |280.0 |565.0 |259.0 |3.8462 |342200.0
|NEAR BAY

|... |... |... |... |... |... |... |... |... |... |...

|20635 |-121.09 |39.48 |25.0 |1665.0 |374.0 |845.0 |330.0 |1.5603
|78100.0 |INLAND

|20636 |-121.21 |39.49 |18.0 |697.0 |150.0 |356.0 |114.0 |2.5568
|77100.0 |INLAND

|20637 |-121.22 |39.43 |17.0 |2254.0 |485.0 |1007.0 |433.0 |1.7000
|92300.0 |INLAND

|20638 |-121.32 |39.43 |18.0 |1860.0 |409.0 |741.0 |349.0 |1.8672
|84700.0 |INLAND

|20639 |-121.24 |39.37 |16.0 |2785.0 |616.0 |1387.0 |530.0 |2.3886
|89400.0 |INLAND
|===

20640 rows Ã— 10 columns
----


+*In[6]:*+
[source, ipython3]
----
df['ocean_proximity'].value_counts()
----


+*Out[6]:*+
----<1H OCEAN     9136
INLAND        6551
NEAR OCEAN    2658
NEAR BAY      2290
ISLAND           5
Name: ocean_proximity, dtype: int64----


+*In[7]:*+
[source, ipython3]
----
df.info()  ## extract information
----


+*Out[7]:*+
----
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 20640 entries, 0 to 20639
Data columns (total 10 columns):
 #   Column              Non-Null Count  Dtype  
---  ------              --------------  -----  
 0   longitude           20640 non-null  float64
 1   latitude            20640 non-null  float64
 2   housing_median_age  20640 non-null  float64
 3   total_rooms         20640 non-null  float64
 4   total_bedrooms      20433 non-null  float64
 5   population          20640 non-null  float64
 6   households          20640 non-null  float64
 7   median_income       20640 non-null  float64
 8   median_house_value  20640 non-null  float64
 9   ocean_proximity     20640 non-null  object 
dtypes: float64(9), object(1)
memory usage: 1.6+ MB
----


+*In[8]:*+
[source, ipython3]
----
## checking Null values in our dataset
df.isnull().sum()
----


+*Out[8]:*+
----longitude               0
latitude                0
housing_median_age      0
total_rooms             0
total_bedrooms        207
population              0
households              0
median_income           0
median_house_value      0
ocean_proximity         0
dtype: int64----


+*In[9]:*+
[source, ipython3]
----
## total_bedrooms  is only feature column having 207 null values 
## we need to replaces these values either using mean or median 
### we choose mean if gap between values is less ,otherwise median
----


+*In[10]:*+
[source, ipython3]
----
df.drop(['longitude','latitude'],axis=1,inplace =True)  ### Removing the  features which are irrelevant for  our model 
----


+*In[11]:*+
[source, ipython3]
----
df.info()
----


+*Out[11]:*+
----
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 20640 entries, 0 to 20639
Data columns (total 8 columns):
 #   Column              Non-Null Count  Dtype  
---  ------              --------------  -----  
 0   housing_median_age  20640 non-null  float64
 1   total_rooms         20640 non-null  float64
 2   total_bedrooms      20433 non-null  float64
 3   population          20640 non-null  float64
 4   households          20640 non-null  float64
 5   median_income       20640 non-null  float64
 6   median_house_value  20640 non-null  float64
 7   ocean_proximity     20640 non-null  object 
dtypes: float64(7), object(1)
memory usage: 1.3+ MB
----


+*In[12]:*+
[source, ipython3]
----
df.shape ## 20640 rows and 8 columns
----


+*Out[12]:*+
----(20640, 8)----


+*In[13]:*+
[source, ipython3]
----
df['total_bedrooms'].fillna(df['total_bedrooms'].mean(),inplace=True)
----


+*In[14]:*+
[source, ipython3]
----
df.info()
----


+*Out[14]:*+
----
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 20640 entries, 0 to 20639
Data columns (total 8 columns):
 #   Column              Non-Null Count  Dtype  
---  ------              --------------  -----  
 0   housing_median_age  20640 non-null  float64
 1   total_rooms         20640 non-null  float64
 2   total_bedrooms      20640 non-null  float64
 3   population          20640 non-null  float64
 4   households          20640 non-null  float64
 5   median_income       20640 non-null  float64
 6   median_house_value  20640 non-null  float64
 7   ocean_proximity     20640 non-null  object 
dtypes: float64(7), object(1)
memory usage: 1.3+ MB
----


+*In[15]:*+
[source, ipython3]
----
df.head() ## to show top 5 data
----


+*Out[15]:*+
----
[cols=",,,,,,,,",options="header",]
|===
| |housing_median_age |total_rooms |total_bedrooms |population
|households |median_income |median_house_value |ocean_proximity
|0 |41.0 |880.0 |129.0 |322.0 |126.0 |8.3252 |452600.0 |NEAR BAY

|1 |21.0 |7099.0 |1106.0 |2401.0 |1138.0 |8.3014 |358500.0 |NEAR BAY

|2 |52.0 |1467.0 |190.0 |496.0 |177.0 |7.2574 |352100.0 |NEAR BAY

|3 |52.0 |1274.0 |235.0 |558.0 |219.0 |5.6431 |341300.0 |NEAR BAY

|4 |52.0 |1627.0 |280.0 |565.0 |259.0 |3.8462 |342200.0 |NEAR BAY
|===
----

== Visualize the data


+*In[16]:*+
[source, ipython3]
----
df.hist(figsize=(20,15))
----


+*Out[16]:*+
----array([[<AxesSubplot:title={'center':'housing_median_age'}>,
        <AxesSubplot:title={'center':'total_rooms'}>,
        <AxesSubplot:title={'center':'total_bedrooms'}>],
       [<AxesSubplot:title={'center':'population'}>,
        <AxesSubplot:title={'center':'households'}>,
        <AxesSubplot:title={'center':'median_income'}>],
       [<AxesSubplot:title={'center':'median_house_value'}>,
        <AxesSubplot:>, <AxesSubplot:>]], dtype=object)
![png](output_16_1.png)
----


+*In[17]:*+
[source, ipython3]
----
### Finding  pairwise correlation between all columns in our dataset using matrix 
### use heatmap with help of seaborn library for advance visualization
----


+*In[18]:*+
[source, ipython3]
----
sns.heatmap(df.corr(),annot=True)
----


+*Out[18]:*+
----<AxesSubplot:>
![png](output_18_1.png)
----


+*In[19]:*+
[source, ipython3]
----
## Analysis : checking the relation between median_income and median_house_value( our target column)
### : checking that is  median_income is less than median_house_value 
----

== plot a graph


+*In[20]:*+
[source, ipython3]
----
sns.scatterplot(data=df,x='median_income',y='median_house_value')
plt.title('Median Income vs Median House value')
----


+*Out[20]:*+
----Text(0.5, 1.0, 'Median Income vs Median House value')
![png](output_21_1.png)
----

== Outliers


+*In[21]:*+
[source, ipython3]
----
sns.boxplot(data=df,y='median_house_value')
----


+*Out[21]:*+
----<AxesSubplot:ylabel='median_house_value'>
![png](output_23_1.png)
----


+*In[22]:*+
[source, ipython3]
----
df['median_house_value'].mean()  # mean of median_house_value
----


+*Out[22]:*+
----206855.81690891474----

== Feature selection

== one hot encoding




+*In[23]:*+
[source, ipython3]
----
from sklearn.preprocessing import OneHotEncoder
ohe = OneHotEncoder(handle_unknown = 'ignore', sparse = False)  ## one hot encoding
df_ohe = pd.DataFrame(ohe.fit_transform(df[['ocean_proximity']]))
----


+*In[24]:*+
[source, ipython3]
----
df_ohe.index = df.index
df_num = df.drop(['ocean_proximity'], axis=1) ## numeric data
df2 = pd.concat([df_num, df_ohe], axis=1) ## categorical data changes into nimeric data
df2.head()
----


+*Out[24]:*+
----
[cols=",,,,,,,,,,,,",options="header",]
|===
| |housing_median_age |total_rooms |total_bedrooms |population
|households |median_income |median_house_value |0 |1 |2 |3 |4
|0 |41.0 |880.0 |129.0 |322.0 |126.0 |8.3252 |452600.0 |0.0 |0.0 |0.0
|1.0 |0.0

|1 |21.0 |7099.0 |1106.0 |2401.0 |1138.0 |8.3014 |358500.0 |0.0 |0.0
|0.0 |1.0 |0.0

|2 |52.0 |1467.0 |190.0 |496.0 |177.0 |7.2574 |352100.0 |0.0 |0.0 |0.0
|1.0 |0.0

|3 |52.0 |1274.0 |235.0 |558.0 |219.0 |5.6431 |341300.0 |0.0 |0.0 |0.0
|1.0 |0.0

|4 |52.0 |1627.0 |280.0 |565.0 |259.0 |3.8462 |342200.0 |0.0 |0.0 |0.0
|1.0 |0.0
|===
----



== separate input features and target value


+*In[25]:*+
[source, ipython3]
----
y = df2.median_house_value  ## y- target column 'median_house_value'
----


+*In[26]:*+
[source, ipython3]
----
y
----


+*Out[26]:*+
----0        452600.0
1        358500.0
2        352100.0
3        341300.0
4        342200.0
           ...   
20635     78100.0
20636     77100.0
20637     92300.0
20638     84700.0
20639     89400.0
Name: median_house_value, Length: 20640, dtype: float64----


+*In[27]:*+
[source, ipython3]
----
X = df2.drop(columns = 'median_house_value')  # remove target column from input features 
----


+*In[28]:*+
[source, ipython3]
----
X.head()
----


+*Out[28]:*+
----
[cols=",,,,,,,,,,,",options="header",]
|===
| |housing_median_age |total_rooms |total_bedrooms |population
|households |median_income |0 |1 |2 |3 |4
|0 |41.0 |880.0 |129.0 |322.0 |126.0 |8.3252 |0.0 |0.0 |0.0 |1.0 |0.0

|1 |21.0 |7099.0 |1106.0 |2401.0 |1138.0 |8.3014 |0.0 |0.0 |0.0 |1.0
|0.0

|2 |52.0 |1467.0 |190.0 |496.0 |177.0 |7.2574 |0.0 |0.0 |0.0 |1.0 |0.0

|3 |52.0 |1274.0 |235.0 |558.0 |219.0 |5.6431 |0.0 |0.0 |0.0 |1.0 |0.0

|4 |52.0 |1627.0 |280.0 |565.0 |259.0 |3.8462 |0.0 |0.0 |0.0 |1.0 |0.0
|===
----

== 2. Choose ML algorithm


+*In[29]:*+
[source, ipython3]
----
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score
----


+*In[34]:*+
[source, ipython3]
----
X.shape
----


+*Out[34]:*+
----(20640, 11)----




+*In[35]:*+
[source, ipython3]
----
from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.2)

----


+*In[36]:*+
[source, ipython3]
----
# x_train
----


+*In[37]:*+
[source, ipython3]
----
#y_train
----


+*In[38]:*+
[source, ipython3]
----
print (x_train.shape)
x_test.shape
----


+*Out[38]:*+
----
(16512, 11)
(4128, 11)----


+*In[ ]:*+
[source, ipython3]
----

----

== 3. Train model using training data ( LinearRegression)


+*In[39]:*+
[source, ipython3]
----
from sklearn.linear_model import LinearRegression

model = LinearRegression()
model.fit(x_train, y_train)
----


+*Out[39]:*+
----LinearRegression()----

== 4. Evaluate on Model test data


+*In[40]:*+
[source, ipython3]
----
y_pred=model.predict(x_test)
----


+*In[41]:*+
[source, ipython3]
----
y_pred
----


+*Out[41]:*+
----array([135932.64677152, 213493.03811531, 208541.07843027, ...,
       165081.76872595, 352973.73612415, 100397.2009691 ])----


+*In[42]:*+
[source, ipython3]
----
y_pred.mean()  # y_pred mean
----


+*Out[42]:*+
----208194.55210420518----

== Model performance accuracy


+*In[ ]:*+
[source, ipython3]
----
from sklearn.metrics import r2_score
----


+*In[43]:*+
[source, ipython3]
----
r2_score(y_test,y_pred)
----


+*Out[43]:*+
----0.6387136421747155----


+*In[46]:*+
[source, ipython3]
----
m=r2_score(y_test, y_pred)

----


+*In[47]:*+
[source, ipython3]
----
m
----


+*Out[47]:*+
----0.6387136421747155----


+*In[50]:*+
[source, ipython3]
----
score=m*100
print("our model is  {} % accurate".format(score))
----


+*Out[50]:*+
----
our model is  63.87136421747155 % accurate
----


+*In[ ]:*+
[source, ipython3]
----

----
